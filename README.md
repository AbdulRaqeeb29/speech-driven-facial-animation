# speech-driven-facial-animation

In this work we have presented an end-to-end model using CGANs for speech-driven facial animation. This model has shown promising results in generating lifelike videos. Moving forward, we believe that different architectures for the sequence discriminator could help produce more natural sequences. Basic model, with only a single image for training the variance in the data is not much. Thus we have observed that if we have enough resources and time.

The dataset we have used in for the training in this project was 'VidTimit', which consists of Audio and Image sequences to predict the model..
